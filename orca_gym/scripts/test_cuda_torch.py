#!/usr/bin/env python3
"""
æµ‹è¯•CUDAå’Œtorchæ˜¯å¦æ­£ç¡®å®‰è£…å’Œå¯ç”¨çš„è„šæœ¬
ç”¨äºéªŒè¯ç¯å¢ƒé…ç½®æ˜¯å¦æ»¡è¶³è¿è¡Œlegged_gymçš„è¦æ±‚
"""

import sys
import subprocess
import platform

from orca_gym.log.orca_log import get_orca_logger
_logger = get_orca_logger()


def check_python_version():
    """æ£€æŸ¥Pythonç‰ˆæœ¬"""
    _logger.info("=" * 50)
    _logger.info("Pythonç‰ˆæœ¬æ£€æŸ¥")
    _logger.info("=" * 50)
    _logger.info(f"Pythonç‰ˆæœ¬: {sys.version}")
    _logger.info(f"Pythonè·¯å¾„: {sys.executable}")
    
    if sys.version_info < (3, 7):
        _logger.info("âŒ Pythonç‰ˆæœ¬è¿‡ä½ï¼Œå»ºè®®ä½¿ç”¨Python 3.7æˆ–æ›´é«˜ç‰ˆæœ¬")
        return False
    else:
        _logger.info("âœ… Pythonç‰ˆæœ¬ç¬¦åˆè¦æ±‚")
        return True

def check_cuda_installation():
    """æ£€æŸ¥CUDAå®‰è£…"""
    _logger.info("\n" + "=" * 50)
    _logger.info("CUDAå®‰è£…æ£€æŸ¥")
    _logger.info("=" * 50)
    
    # æ£€æŸ¥nvidia-smiå‘½ä»¤
    try:
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, timeout=10)
        if result.returncode == 0:
            _logger.info("âœ… nvidia-smiå‘½ä»¤å¯ç”¨")
            _logger.info("GPUä¿¡æ¯:")
            _logger.info(result.stdout)
        else:
            _logger.info("âŒ nvidia-smiå‘½ä»¤ä¸å¯ç”¨")
            return False
    except FileNotFoundError:
        _logger.info("âŒ æœªæ‰¾åˆ°nvidia-smiå‘½ä»¤ï¼Œå¯èƒ½CUDAæœªå®‰è£…æˆ–PATHä¸­æœªåŒ…å«")
        return False
    except subprocess.TimeoutExpired:
        _logger.info("âŒ nvidia-smiå‘½ä»¤æ‰§è¡Œè¶…æ—¶")
        return False
    
    # æ£€æŸ¥CUDAç‰ˆæœ¬
    try:
        result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True, timeout=10)
        if result.returncode == 0:
            _logger.info("âœ… nvccå‘½ä»¤å¯ç”¨")
            # æå–CUDAç‰ˆæœ¬
            for line in result.stdout.split('\n'):
                if 'release' in line.lower():
                    _logger.info(f"CUDAç‰ˆæœ¬: {line.strip()}")
                    break
        else:
            _logger.info("âŒ nvccå‘½ä»¤ä¸å¯ç”¨")
            return False
    except FileNotFoundError:
        _logger.info("âŒ æœªæ‰¾åˆ°nvccå‘½ä»¤ï¼Œå¯èƒ½CUDA toolkitæœªå®‰è£…æˆ–PATHä¸­æœªåŒ…å«")
        return False
    except subprocess.TimeoutExpired:
        _logger.info("âŒ nvccå‘½ä»¤æ‰§è¡Œè¶…æ—¶")
        return False
    
    return True

def check_torch_installation():
    """æ£€æŸ¥torchå®‰è£…"""
    _logger.info("\n" + "=" * 50)
    _logger.info("PyTorchå®‰è£…æ£€æŸ¥")
    _logger.info("=" * 50)
    
    try:
        import torch
        _logger.info(f"âœ… PyTorchç‰ˆæœ¬: {torch.__version__}")
        
        # æ£€æŸ¥CUDAæ˜¯å¦å¯ç”¨
        if torch.cuda.is_available():
            _logger.info("âœ… PyTorch CUDAæ”¯æŒå·²å¯ç”¨")
            _logger.info(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")
            _logger.info(f"cuDNNç‰ˆæœ¬: {torch.backends.cudnn.version()}")
            _logger.info(f"å¯ç”¨GPUæ•°é‡: {torch.cuda.device_count()}")
            
            # æ˜¾ç¤ºGPUä¿¡æ¯
            for i in range(torch.cuda.device_count()):
                gpu_name = torch.cuda.get_device_name(i)
                gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1024**3
                _logger.info(f"GPU {i}: {gpu_name} ({gpu_memory:.1f} GB)")
            
            # æµ‹è¯•CUDAå¼ é‡æ“ä½œ
            try:
                x = torch.randn(1000, 1000).cuda()
                y = torch.randn(1000, 1000).cuda()
                z = torch.mm(x, y)
                _logger.info("âœ… CUDAå¼ é‡è¿ç®—æµ‹è¯•é€šè¿‡")
            except Exception as e:
                _logger.info(f"âŒ CUDAå¼ é‡è¿ç®—æµ‹è¯•å¤±è´¥: {e}")
                return False
                
        else:
            _logger.info("âŒ PyTorch CUDAæ”¯æŒæœªå¯ç”¨")
            _logger.info("å¯èƒ½çš„åŸå› :")
            _logger.info("1. å®‰è£…çš„æ˜¯CPUç‰ˆæœ¬çš„PyTorch")
            _logger.info("2. CUDAç‰ˆæœ¬ä¸PyTorchä¸åŒ¹é…")
            _logger.info("3. ç¯å¢ƒå˜é‡é…ç½®é—®é¢˜")
            return False
            
    except ImportError:
        _logger.info("âŒ PyTorchæœªå®‰è£…")
        return False
    except Exception as e:
        _logger.info(f"âŒ PyTorchæ£€æŸ¥è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        return False
    
    return True

def check_system_info():
    """æ£€æŸ¥ç³»ç»Ÿä¿¡æ¯"""
    _logger.info("\n" + "=" * 50)
    _logger.info("ç³»ç»Ÿä¿¡æ¯")
    _logger.info("=" * 50)
    _logger.info(f"æ“ä½œç³»ç»Ÿ: {platform.system()}")
    _logger.info(f"ç³»ç»Ÿç‰ˆæœ¬: {platform.release()}")
    _logger.info(f"æ¶æ„: {platform.machine()}")
    _logger.info(f"å¤„ç†å™¨: {platform.processor()}")

def main():
    """ä¸»å‡½æ•°"""
    _logger.info("CUDAå’ŒPyTorchç¯å¢ƒæ£€æŸ¥å·¥å…·")
    _logger.info("ç”¨äºéªŒè¯legged_gymè¿è¡Œç¯å¢ƒ")
    
    # æ£€æŸ¥ç³»ç»Ÿä¿¡æ¯
    check_system_info()
    
    # æ£€æŸ¥Pythonç‰ˆæœ¬
    python_ok = check_python_version()
    
    # æ£€æŸ¥CUDAå®‰è£…
    cuda_ok = check_cuda_installation()
    
    # æ£€æŸ¥PyTorchå®‰è£…
    torch_ok = check_torch_installation()
    
    # æ€»ç»“
    _logger.info("\n" + "=" * 50)
    _logger.info("æ£€æŸ¥ç»“æœæ€»ç»“")
    _logger.info("=" * 50)
    
    if python_ok and cuda_ok and torch_ok:
        _logger.info("ğŸ‰ æ‰€æœ‰æ£€æŸ¥éƒ½é€šè¿‡äº†ï¼ç¯å¢ƒé…ç½®æ­£ç¡®ï¼Œå¯ä»¥ç»§ç»­åç»­æ­¥éª¤ã€‚")
        return True
    else:
        _logger.info("âš ï¸  å­˜åœ¨ä¸€äº›é—®é¢˜ï¼Œè¯·æ ¹æ®ä¸Šè¿°æç¤ºè¿›è¡Œä¿®å¤ï¼š")
        if not python_ok:
            _logger.info("- å‡çº§Pythonç‰ˆæœ¬")
        if not cuda_ok:
            _logger.info("- å®‰è£…æˆ–é…ç½®CUDA")
        if not torch_ok:
            _logger.info("- é‡æ–°å®‰è£…åŒ¹é…çš„PyTorchç‰ˆæœ¬")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 