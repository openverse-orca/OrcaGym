#!/usr/bin/env python3
"""
XBotè¿è¡Œè„šæœ¬ - å®Œå…¨åŸºäºOrcaGymæ¡†æ¶
ä½¿ç”¨envs/xbot_gym/xbot_simple_env.pyç¯å¢ƒ
"""

from datetime import datetime
import sys
import os
import time
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '../..'))

from envs.xbot_gym.xbot_simple_env import XBotSimpleEnv
import torch
import numpy as np
import math

def print_detailed_diagnostics(step, obs, action, env):
    """
    â­ è¯¦ç»†è¯Šæ–­è¾“å‡º - å‚è€ƒstandaloneMujocoçš„è°ƒè¯•æ ¼å¼
    """
    print(f"\n{'='*80}")
    print(f"ğŸ” è¯¦ç»†è¯Šæ–­ [Step={step}, Policy Update={step//10}, Time={step*0.001:.2f}s]")
    print(f"{'='*80}")
    
    # è§£æè§‚æµ‹ç©ºé—´ï¼ˆ47ç»´ï¼‰
    phase_sin, phase_cos = obs[0], obs[1]
    phase = math.atan2(phase_sin, phase_cos) / (2 * math.pi)
    if phase < 0:
        phase += 1.0
    
    cmd_vx = obs[2] / 2.0   # æ¢å¤åŸå§‹å‘½ä»¤
    cmd_vy = obs[3] / 2.0
    cmd_dyaw = obs[4] / 1.0
    
    q_obs = obs[5:17]         # å…³èŠ‚ä½ç½®åå·®
    dq_obs = obs[17:29] / 0.05  # å…³èŠ‚é€Ÿåº¦ï¼ˆæ¢å¤ï¼‰
    last_action = obs[29:41]  # ä¸Šä¸€æ¬¡åŠ¨ä½œ
    omega = obs[41:44]        # è§’é€Ÿåº¦
    euler = obs[44:47]        # æ¬§æ‹‰è§’
    
    print(f"\nğŸ“Š è§‚æµ‹ç©ºé—´ (47ç»´):")
    print(f"  - Gait Phase: {phase:.3f} (sin={phase_sin:.3f}, cos={phase_cos:.3f})")
    print(f"  - Commands: vx={cmd_vx:.2f}, vy={cmd_vy:.2f}, dyaw={cmd_dyaw:.2f}")
    print(f"  - Joint Pos: range=[{q_obs.min():.3f}, {q_obs.max():.3f}], mean={q_obs.mean():.3f}")
    print(f"  - Joint Vel: range=[{dq_obs.min():.2f}, {dq_obs.max():.2f}], mean={dq_obs.mean():.2f}")
    print(f"  - Last Action: range=[{last_action.min():.3f}, {last_action.max():.3f}], mean={last_action.mean():.3f}")
    print(f"  - Angular Vel: [{omega[0]:.2f}, {omega[1]:.2f}, {omega[2]:.2f}]")
    print(f"  - Euler: [{np.rad2deg(euler[0]):.1f}Â°, {np.rad2deg(euler[1]):.1f}Â°, {np.rad2deg(euler[2]):.1f}Â°]")
    
    print(f"\nğŸ® åŠ¨ä½œè¾“å‡º (12ç»´):")
    print(f"  - Action: range=[{action.min():.3f}, {action.max():.3f}], mean={action.mean():.3f}")
    print(f"  - Action norm: {np.linalg.norm(action):.3f}")
    
    # PDæ§åˆ¶ä¿¡æ¯ï¼ˆä»ç¯å¢ƒè·å–ï¼‰
    if hasattr(env, 'last_tau'):
        tau = env.last_tau
        print(f"\nâš™ï¸  PDæ§åˆ¶:")
        print(f"  - Target q: range=[{(env.action_scale * action).min():.3f}, {(env.action_scale * action).max():.3f}]")
        print(f"  - Torque Ï„: range=[{tau.min():.1f}, {tau.max():.1f}] NÂ·m, max_abs={np.abs(tau).max():.1f}")
        print(f"  - Torque usage: {np.abs(tau).max()/env.tau_limit*100:.1f}% of limit")
    
    # BaseçŠ¶æ€
    if hasattr(env, 'last_base_pos'):
        base_pos = env.last_base_pos
        print(f"\nğŸ¤– BaseçŠ¶æ€:")
        print(f"  - Position: ({base_pos[0]:.3f}, {base_pos[1]:.3f}, {base_pos[2]:.3f})m")
        print(f"  - RPY: ({np.rad2deg(euler[0]):.2f}Â°, {np.rad2deg(euler[1]):.2f}Â°, {np.rad2deg(euler[2]):.2f}Â°)")
    
    print(f"{'='*80}")


def main():
    print("="*80)
    print("ğŸš€ XBotè¿è¡Œæµ‹è¯• - OrcaGymæ¡†æ¶ï¼ˆå¢å¼ºè¯Šæ–­ç‰ˆï¼‰")
    print("="*80)
    
    # å…³é”®é…ç½® - åŒ¹é…humanoid-gym
    config = {
        "frame_skip": 10,              # å•æ¬¡ç‰©ç†æ­¥
        "orcagym_addr": "localhost:50051",
        "agent_names": ["XBot-L"],
        "time_step": 0.001,           # âš ï¸ 1msç‰©ç†æ­¥é•¿
        "max_episode_steps": 10000,
        "render_mode": "human",       # å¯è§†åŒ–
    }

    TIME_STEP = config['time_step']
    FRAME_SKIP = config['frame_skip']
    REALTIME_STEP = TIME_STEP * FRAME_SKIP
    
    # â­ å‘½ä»¤é€Ÿåº¦é…ç½®ï¼ˆå¯è°ƒèŠ‚å‚æ•°ï¼‰
    # æµ‹è¯•ç»“æœ: 0.4 m/s æ˜¯æœ€ä¼˜é€Ÿåº¦ï¼ˆ262æ­¥ï¼‰ï¼Œé™é€Ÿåè€Œæ€§èƒ½ä¸‹é™
    # é€Ÿåº¦é€‰é¡¹:
    #   - 0.4 m/s: 262æ­¥ âœ… æœ€ä½³æ€§èƒ½
    #   - 0.2 m/s: 232æ­¥ âš ï¸ ç•¥æœ‰ä¸‹é™
    #   - 0.15 m/s: 150æ­¥ âŒ æ€§èƒ½å·®
    CMD_VX = 0.0   # å‰å‘é€Ÿåº¦ï¼ˆä¿æŒ0.4 m/sæœ€ä¼˜ï¼‰
    CMD_VY = 0.0   # ä¾§å‘é€Ÿåº¦
    CMD_DYAW = 0.0 # è½¬å‘é€Ÿåº¦
    
    print(f"\nâš™ï¸  ä»¿çœŸé…ç½®:")
    print(f"  - ç‰©ç†æ­¥é•¿: {config['time_step']}s (1000Hz)")
    print(f"  - Decimation: 10 (åœ¨ç¯å¢ƒå†…éƒ¨å®ç°)")
    print(f"  - ç­–ç•¥é¢‘ç‡: 100Hz")
    print(f"\nğŸ¯ å‘½ä»¤é€Ÿåº¦ (å‚è€ƒstandaloneMujoco):")
    print(f"  - vx: {CMD_VX} m/s")
    print(f"  - vy: {CMD_VY} m/s")
    print(f"  - dyaw: {CMD_DYAW} rad/s")
    
    # åˆ›å»ºç¯å¢ƒ
    print("\nğŸ“¦ åˆ›å»ºç¯å¢ƒ...")
    env = XBotSimpleEnv(**config)
    
    # â­ è®¾ç½®å‘½ä»¤é€Ÿåº¦
    env.cmd_vx = CMD_VX
    env.cmd_vy = CMD_VY
    env.cmd_dyaw = CMD_DYAW
    
    print(f"âœ“ ç¯å¢ƒåˆ›å»ºæˆåŠŸ")
    print(f"  - è§‚æµ‹ç©ºé—´: {env.observation_space.shape}")
    print(f"  - åŠ¨ä½œç©ºé—´: {env.action_space.shape}")
    print(f"  - å‘½ä»¤é€Ÿåº¦å·²è®¾ç½®: vx={env.cmd_vx}, vy={env.cmd_vy}, dyaw={env.cmd_dyaw}")
    
    # åŠ è½½ç­–ç•¥ - ä½¿ç”¨ç›¸å¯¹è·¯å¾„
    # ç›®å½•ç»“æ„: OrcaWorkStation/OrcaGym/examples/xbot/ å’Œ OrcaWorkStation/humanoid-gym/
    policy_path = "../../../humanoid-gym/logs/XBot_ppo/exported/policies/policy_example.pt"
    
    print(f"\nğŸ“¦ åŠ è½½ç­–ç•¥: {policy_path}")
    try:
        policy = torch.jit.load(policy_path)
        policy.eval()
        print(f"âœ“ ç­–ç•¥åŠ è½½æˆåŠŸ")
        use_policy = True
    except Exception as e:
        print(f"\nâš ï¸  æ— æ³•åŠ è½½ç­–ç•¥: {e}")
        print("   ä½¿ç”¨é›¶åŠ¨ä½œæµ‹è¯•")
        use_policy = False
    
    # è¿è¡Œ
    print("\n" + "="*80)
    print("ğŸš€ å¼€å§‹è¿è¡Œ...")
    print("="*80)
    print("\næç¤º:")
    print("  - Pitchåº”è¯¥ä¿æŒ<20Â°ï¼Œé«˜åº¦åº”è¯¥åœ¨0.85-0.95m")
    print("  - æ¯100æ­¥æ‰“å°è¯¦ç»†è¯Šæ–­ä¿¡æ¯")
    print("  - å‚è€ƒstandaloneMujoco: PitchÂ±1.5Â°ï¼Œé€Ÿåº¦0.4m/s\n")
    
    obs, info = env.reset()
    
    episode_reward = 0.0
    episode_steps = 0
    max_steps = 2000  # æµ‹è¯•2000æ­¥
    
    # â­ è¯Šæ–­é—´éš”
    DIAGNOSTIC_INTERVAL = 100  # æ¯100æ­¥æ‰“å°ä¸€æ¬¡è¯¦ç»†è¯Šæ–­
    
    try:
        while True:
            # è·å–action
            start_time = datetime.now()
            if use_policy:
                with torch.no_grad():
                    obs_tensor = torch.from_numpy(obs).float()
                    action = policy(obs_tensor).numpy()
            else:
                # é›¶åŠ¨ä½œï¼ˆç«™ç«‹æµ‹è¯•ï¼‰
                action = np.zeros(12, dtype=np.float32)
            
            # â­ æ¯100æ­¥æ‰“å°è¯¦ç»†è¯Šæ–­ï¼ˆåœ¨stepä¹‹å‰ï¼Œè§‚å¯Ÿè¾“å…¥ï¼‰
            # if step > 0 and step % DIAGNOSTIC_INTERVAL == 0:
            #     print_detailed_diagnostics(step, obs, action, env)
            
            # Step
            obs, reward, terminated, truncated, info = env.step(action)
            
            episode_reward += reward
            episode_steps += 1
            
            # æ¸²æŸ“
            env.render()
            
            # Episodeç»“æŸ
            if terminated or truncated:
                print(f"\n{'='*80}")
                print(f"âŒ Episodeç»“æŸ")
                print(f"{'='*80}")
                print(f"  - Steps: {episode_steps}")
                print(f"  - Reward: {episode_reward:.2f}")
                if 'fall_reason' in info and info['fall_reason']:
                    print(f"  - åŸå› : {info['fall_reason']}")
                print(f"{'='*80}\n")
                
                # æ‰“å°æœ€åçš„è¯Šæ–­ä¿¡æ¯
                # print_detailed_diagnostics(episode_steps, obs, action, env)
                
                obs, info = env.reset()
                episode_reward = 0.0
                episode_steps = 0

            elapsed_time = datetime.now() - start_time
            if elapsed_time.total_seconds() < REALTIME_STEP:
                time.sleep(REALTIME_STEP - elapsed_time.total_seconds())
        # print(f"\n{'='*80}")
        # print(f"âœ… æµ‹è¯•å®Œæˆï¼è¿è¡Œäº†{max_steps}æ­¥")
        # print(f"{'='*80}")
    
    except KeyboardInterrupt:
        print("\n\nâš ï¸  è¿è¡Œè¢«ä¸­æ–­")
    
    finally:
        env.close()
        print("\nç¯å¢ƒå·²å…³é—­")

if __name__ == "__main__":
    main()

